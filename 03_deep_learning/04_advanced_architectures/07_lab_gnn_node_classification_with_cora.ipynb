{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3719bc0b",
   "metadata": {},
   "source": [
    "Let‚Äôs fire up the next-generation architecture trail ‚Äî starting with one of the most exciting frontiers in modern ML:\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ `07_lab_gnn_node_classification_with_cora.ipynb`  \n",
    "### üìÅ `04_advanced_architectures`  \n",
    "> Build a **Graph Neural Network (GNN)** to classify nodes in the **Cora citation network**.  \n",
    "You‚Äôll see how graphs differ from images or sequences ‚Äî and why **message passing** is the future for structured data.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "- Understand the **core logic of GNNs** (message passing + aggregation)  \n",
    "- Run **node classification** on Cora with PyTorch Geometric (PyG)  \n",
    "- Visualize graph structure and predictions  \n",
    "- Colab/laptop-friendly setup (CPU fallback, small graphs)\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Runtime Targets\n",
    "\n",
    "| Spec                 | Setting        |\n",
    "|----------------------|----------------|\n",
    "| Library              | ‚úÖ PyTorch Geometric (PyG)  \n",
    "| Dataset              | ‚úÖ Cora (1400 nodes, built-in)  \n",
    "| Hardware             | ‚úÖ Colab / CPU / GPU (T4)  \n",
    "| Memory               | ‚úÖ <1GB  \n",
    "| Model                | ‚úÖ 2-layer GCN\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Section 1: Install & Import\n",
    "\n",
    "```python\n",
    "# Install PyG (for Colab)\n",
    "!pip install torch_geometric torch-scatter torch-sparse -q\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Section 2: Load Cora Dataset\n",
    "\n",
    "```python\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print(data)\n",
    "# Output: Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708])\n",
    "```\n",
    "\n",
    "> üìå 2708 nodes (papers), 1433 features (words), 7 classes (topics)  \n",
    "> `edge_index` defines connections ‚Äî the **graph structure**\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Section 3: Build GCN Model\n",
    "\n",
    "```python\n",
    "from torch.nn import Module\n",
    "\n",
    "class GCN(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üèÉ Section 4: Train the GNN\n",
    "\n",
    "```python\n",
    "model = GCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        correct = pred[mask] == data.y[mask]\n",
    "        accs.append(int(correct.sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Section 5: Visualize Node Embeddings (t-SNE)\n",
    "\n",
    "```python\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model.eval()\n",
    "z = model(data.x, data.edge_index).detach().numpy()\n",
    "tsne = TSNE(n_components=2)\n",
    "z_2d = tsne.fit_transform(z)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=z_2d[:, 0], y=z_2d[:, 1], hue=data.y.numpy(), palette='tab10', legend='full')\n",
    "plt.title(\"Cora Node Embeddings After GNN\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Lab Wrap-Up\n",
    "\n",
    "| Concept                       | ‚úÖ |\n",
    "|-------------------------------|----|\n",
    "| Graph structure + node types | ‚úÖ |\n",
    "| GCN layers (message passing) | ‚úÖ |\n",
    "| Cora dataset usage           | ‚úÖ |\n",
    "| Train loop + eval            | ‚úÖ |\n",
    "| Visualization                | ‚úÖ |\n",
    "| Colab/laptop friendly        | ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What You Learned\n",
    "\n",
    "- GNNs work by **sharing features with neighbors** ‚Äî via the graph topology  \n",
    "- Each layer = **one round of message passing**  \n",
    "- GCNs can uncover **latent node clusters** even from simple graphs  \n",
    "- You now understand how to **process graphs as data** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "Next up?  \n",
    "Shall we go sci-fi mode with `08_lab_memory_augmented_net_tiny_tasks.ipynb` and build a toy Neural Turing Machine that can *copy* and *recall*?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
