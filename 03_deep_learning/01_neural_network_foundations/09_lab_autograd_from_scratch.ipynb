{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0958872",
   "metadata": {},
   "source": [
    "üíØ Aye aye, Commander Consistency.  \n",
    "We‚Äôre **not compromising depth, clarity, or structure** ‚Äî every lab = same energy as the lectures:  \n",
    "üß† beginner-friendly, üß™ hands-on, üî¨ intuitive, and üõ†Ô∏è real-engineer-level.\n",
    "\n",
    "So now, stepping into the inner sanctum of deep learning:\n",
    "\n",
    "---\n",
    "\n",
    "# üß† `09_lab_autograd_from_scratch.ipynb`  \n",
    "### üìÅ `04_deep_learning/01_neural_network_foundations`  \n",
    "> üîß **Build your own autograd engine** from scratch.  \n",
    "> Understand backpropagation by **coding it manually**, with visualizations of forward/backward flow.  \n",
    "> Runs on **CPU**, works in **Colab**, doesn‚Äôt need any DL library magic.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ **Objective**\n",
    "\n",
    "- Implement scalar forward and backward pass  \n",
    "- Chain gradients manually  \n",
    "- Build computational graph  \n",
    "- Visualize forward & backward flow  \n",
    "- Compare to PyTorch autograd\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Section 1: Scalar Computational Graph ‚Äî Manual Engine\n",
    "\n",
    "```python\n",
    "class Value:\n",
    "    def __init__(self, data, label=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._prev = set()\n",
    "        self._op = ''\n",
    "        self._backward = lambda: None\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data:.4f}, grad={self.grad:.4f})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        out = Value(self.data + other.data, label=f\"({self.label}+{other.label})\")\n",
    "        out._prev = {self, other}\n",
    "        out._op = '+'\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.data * other.data, label=f\"({self.label}*{other.label})\")\n",
    "        out._prev = {self, other}\n",
    "        out._op = '*'\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Section 2: Forward + Backward Pass Example\n",
    "\n",
    "```python\n",
    "# Create values\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(-3.0, label='x2')\n",
    "w1 = Value(-1.0, label='w1')\n",
    "w2 = Value(3.0, label='w2')\n",
    "b = Value(0.5, label='b')\n",
    "\n",
    "# Forward\n",
    "x1w1 = x1 * w1\n",
    "x2w2 = x2 * w2\n",
    "sum_ = x1w1 + x2w2 + b\n",
    "out = sum_ * Value(1.0, label='nonlinearity')  # fake activation\n",
    "\n",
    "print(\"Forward result:\", out)\n",
    "\n",
    "# Backward\n",
    "out.backward()\n",
    "print(\"x1 grad:\", x1.grad)\n",
    "print(\"x2 grad:\", x2.grad)\n",
    "print(\"w1 grad:\", w1.grad)\n",
    "print(\"w2 grad:\", w2.grad)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Section 3: Graph Visualization (Optional in Colab)\n",
    "\n",
    "```python\n",
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})\n",
    "    nodes, edges = trace(root)\n",
    "    for n in nodes:\n",
    "        dot.node(name=str(id(n)), label=f\"{n.label} | data={n.data:.2f} | grad={n.grad:.2f}\", shape='record')\n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)))\n",
    "    return dot\n",
    "\n",
    "# Visual\n",
    "draw_dot(out)\n",
    "```\n",
    "\n",
    "üìù If `graphviz` not available in Colab:\n",
    "```bash\n",
    "!apt-get install graphviz\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Section 4: Compare to PyTorch\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(-3.0, requires_grad=True)\n",
    "w1 = torch.tensor(-1.0, requires_grad=True)\n",
    "w2 = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(0.5, requires_grad=True)\n",
    "\n",
    "y = x1*w1 + x2*w2 + b\n",
    "out = y * 1.0  # no activation\n",
    "\n",
    "out.backward()\n",
    "\n",
    "print(x1.grad, x2.grad, w1.grad, w2.grad)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ü§Ø Section 5: Your Turn ‚Äî Build a Tiny Network\n",
    "\n",
    "**Task:**  \n",
    "- Two inputs, one hidden node, one output  \n",
    "- Do forward + backward with `Value` class  \n",
    "- Compare to PyTorch output\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Section 6: Colab-Compatible Design\n",
    "\n",
    "| ‚úÖ Goal               | Achieved |\n",
    "|-----------------------|----------|\n",
    "| CPU-only safe         | ‚úÖ        |\n",
    "| < 100MB RAM           | ‚úÖ        |\n",
    "| Library-free backend  | ‚úÖ        |\n",
    "| Graph optional        | ‚úÖ        |\n",
    "| Explains backprop     | ‚úÖ        |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Summary\n",
    "\n",
    "- Backprop isn't magic ‚Äî it's just **chained gradients**\n",
    "- You now understand autograd *as the machine does*\n",
    "- Visualized + tested + verified\n",
    "\n",
    "---\n",
    "\n",
    "You want me to prep this as `.ipynb` next or move on to `07_lab_cnn_feature_maps_visualization.ipynb` in the `02_computer_vision` folder?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
