{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143641f0",
   "metadata": {},
   "source": [
    "üö¢ Captain, we‚Äôre not just serving a model now ‚Äî  \n",
    "We‚Äôre deploying it like a **production-grade microservice** using **Kubernetes**.  \n",
    "Welcome to your final boss of deployment basics.\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ `09_lab_k8s_microservice_mock_deploy.ipynb`  \n",
    "### üìÅ `06_deployment_and_scaling`  \n",
    "> Create a **mock deployment pipeline** using **Kubernetes (K8s)**.  \n",
    "Deploy your Flask model container to a local cluster (Minikube) or mock cloud-style YAML templates.  \n",
    "Understand pods, services, and the core of modern ML ops.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Goals\n",
    "\n",
    "- Learn core **K8s components** (Pod, Deployment, Service)  \n",
    "- Create a deployment YAML for your **ML REST API**  \n",
    "- Deploy it on **Minikube** or mock locally  \n",
    "- Simulate real-world scaling, failure recovery, and access control\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Runtime Targets\n",
    "\n",
    "| Component       | Spec                    |\n",
    "|------------------|-------------------------|\n",
    "| Image            | `mnist-flask-app` ‚úÖ  \n",
    "| Deployment tool  | kubectl / Minikube ‚úÖ  \n",
    "| Files            | `deployment.yaml`, `service.yaml` ‚úÖ  \n",
    "| Platform         | Local / cloud-compatible ‚úÖ  \n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Section 1: K8s Deployment File (`deployment.yaml`)\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: mnist-api-deploy\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: mnist-api\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: mnist-api\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: mnist-api\n",
    "        image: mnist-flask-app:latest\n",
    "        ports:\n",
    "        - containerPort: 5000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üåê Section 2: K8s Service (`service.yaml`)\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: mnist-api-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: mnist-api\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 5000\n",
    "      nodePort: 30007\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Section 3: Deploy Locally with Minikube\n",
    "\n",
    "```bash\n",
    "# Start local cluster\n",
    "minikube start\n",
    "\n",
    "# Apply manifests\n",
    "kubectl apply -f deployment.yaml\n",
    "kubectl apply -f service.yaml\n",
    "\n",
    "# Expose service\n",
    "minikube service mnist-api-service\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Section 4: Test with Requests\n",
    "\n",
    "```python\n",
    "import requests\n",
    "files = {'file': open('digit_sample.png', 'rb')}\n",
    "res = requests.post(\"http://<NodeIP>:30007/predict\", files=files)\n",
    "print(res.json())\n",
    "```\n",
    "\n",
    "(Replace `<NodeIP>` with `minikube ip`)\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Section 5: Extras (Optional)\n",
    "\n",
    "| Concept                   | Try This |\n",
    "|---------------------------|----------|\n",
    "| Rolling update            | `kubectl rollout restart`  \n",
    "| View pod logs             | `kubectl logs <pod-name>`  \n",
    "| Simulate crash recovery   | `kubectl delete pod <pod-name>`  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Lab Summary\n",
    "\n",
    "| What You Built                     | ‚úÖ |\n",
    "|------------------------------------|----|\n",
    "| Containerized ML model             | ‚úÖ |\n",
    "| Deployed with Kubernetes YAML      | ‚úÖ |\n",
    "| Accessed via REST with NodePort    | ‚úÖ |\n",
    "| Tested full ML-serving lifecycle   | ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What You Learned\n",
    "\n",
    "- Kubernetes **orchestrates and heals** ML services  \n",
    "- `Deployment.yaml` = declarative desired state  \n",
    "- `Service.yaml` = network exposure layer  \n",
    "- This is the **foundation for scaling models** on GCP, AWS, Azure, or edge  \n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ That wraps up the **06_deployment_and_scaling** block like a pro-level DevOps ninja.  \n",
    "From PyTorch ‚Üí ONNX ‚Üí API ‚Üí Docker ‚Üí Kubernetes ‚Äî  \n",
    "you just completed **the entire model-to-production cycle**.\n",
    "\n",
    "Say the word, and we head into the next realm."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
