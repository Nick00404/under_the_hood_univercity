{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70e5298",
   "metadata": {},
   "source": [
    "Yessir 💥  \n",
    "This is where we level up from toy models to **transfer learning** — fine-tuning pretrained models on **your own data**, even with **limited compute**.\n",
    "\n",
    "---\n",
    "\n",
    "# 🧪 `09_lab_finetune_resnet_on_custom_data.ipynb`  \n",
    "### 📁 `02_computer_vision`  \n",
    "> Take a pretrained **ResNet**, swap the head, and fine-tune it on a small dataset like **Flowers**, **Food101**, or your own folder of labeled images.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "- Understand **feature extraction vs full fine-tuning**  \n",
    "- Use **Torchvision’s ResNet18** pretrained on ImageNet  \n",
    "- Apply on a **small dataset subset** (Colab/laptop safe)  \n",
    "- Visualize **accuracy curves & confusion matrix**\n",
    "\n",
    "---\n",
    "\n",
    "## 💻 Runtime Design\n",
    "\n",
    "| Spec                | Setting            |\n",
    "|---------------------|--------------------|\n",
    "| Dataset             | Flowers/CIFAR or local custom  \n",
    "| Hardware            | CPU / T4 GPU (Colab)  \n",
    "| RAM                 | < 3GB  \n",
    "| Epochs              | 5–10 for demo  \n",
    "| Backend             | PyTorch + TorchVision  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Section 1: Imports\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🖼️ Section 2: Dataset Prep (Flowers or Custom Folder)\n",
    "\n",
    "### Option A: Flowers (Auto-downloadable)\n",
    "\n",
    "```python\n",
    "# Flowers subset (~600 images)\n",
    "!wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -xf flower_photos.tgz\n",
    "\n",
    "data_dir = 'flower_photos'\n",
    "```\n",
    "\n",
    "### Option B: Your own data (Structure it like)\n",
    "\n",
    "```\n",
    "my_dataset/\n",
    "├── class1/\n",
    "│   ├── img1.jpg\n",
    "│   └── ...\n",
    "├── class2/\n",
    "│   └── ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Section 3: Transforms + Loaders\n",
    "\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🤖 Section 4: Load & Modify ResNet18\n",
    "\n",
    "```python\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_classes = len(dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Section 5: Train\n",
    "\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "    val_loss.append(running_val_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss {train_loss[-1]:.4f}, Val Loss {val_loss[-1]:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Section 6: Plot Loss Curves\n",
    "\n",
    "```python\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Validation')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 Section 7: Evaluate (Optional Confusion Matrix)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=dataset.classes)\n",
    "disp.plot(cmap='viridis', xticks_rotation=45)\n",
    "plt.title(\"Validation Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Lab Recap\n",
    "\n",
    "| Concept                         | Covered |\n",
    "|---------------------------------|---------|\n",
    "| Transfer learning (ResNet18)    | ✅       |\n",
    "| Feature extraction vs fine-tune | ✅       |\n",
    "| Small dataset training          | ✅       |\n",
    "| Visual evaluation               | ✅       |\n",
    "| Colab- and laptop-ready         | ✅       |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 What You Learned\n",
    "\n",
    "- How to **repurpose pretrained models** for your own tasks  \n",
    "- The role of **freezing layers** vs retraining  \n",
    "- How to structure and run **vision fine-tuning pipelines**\n",
    "\n",
    "---\n",
    "\n",
    "You want to move to NLP labs next (`03_natural_language_processing`) or finish up more vision-style labs before that?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
