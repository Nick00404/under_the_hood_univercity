# ðŸ“˜ ML Basics: Supervised, Unsupervised & RL Demystified

Welcome to **ML Basics** â€” the tactical machine learning track of **UTHU** (Under The Hood University).

This is the phase where abstract math meets **actual learning systems**.  
Youâ€™ll cover everything from classic regression to decision trees, clustering, and reinforcement learning.

---

## ðŸ§­ Track Overview

Weâ€™ve split this into **4 core modules**:
1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning
4. Model Evaluation & Interpretation

Each one builds conceptual + coding depth, paired with notebook exercises and visual demos.

---

## ðŸ§  1. Supervised Learning

> _Teach the model using labeled data, just like a student learning from answers._

| Notebook | Topic |
|----------|-------|
| `01_linear_regression_and_cost_functions.ipynb` | Line fitting, MSE, gradient intuition |
| `02_logistic_regression_and_classification_metrics.ipynb` | Classification, sigmoid, confusion matrix |
| `03_decision_trees_and_ensemble_methods.ipynb` | Gini, entropy, Random Forests, boosting |
| `04_svm_and_kernel_tricks_for_nonlinear_data.ipynb` | Margin maximization, kernels, RBF |
| `05_regularization_l1_l2_elasticnet.ipynb` | Overfitting control via Ridge, Lasso |
| `06_bayesian_models_and_naive_bayes.ipynb` | Probabilistic models, text classification, Bayes rule |

---

## ðŸ§© 2. Unsupervised Learning

> _Let the model find structure in the data without answers._

| Notebook | Topic |
|----------|-------|
| `01_kmeans_clustering_and_elbow_method.ipynb` | Cluster formation, silhouette scores |
| `02_hierarchical_clustering_and_dendrograms.ipynb` | Tree-based clustering, linkage metrics |
| `03_pca_for_dimensionality_reduction.ipynb` | Variance preservation, eigen decomposition |
| `04_autoencoders_for_feature_learning.ipynb` | Neural compression, denoising |
| `05_anomaly_detection_with_isolation_forests.ipynb` | Detecting rare patterns |
| `06_manifold_learning_with_umap_tsne.ipynb` | High-dimensional data visualization |

---

## ðŸ¤– 3. Reinforcement Learning

> _Learning through trial, reward, and exploration._

| Notebook | Topic |
|----------|-------|
| `01_markov_decision_processes_and_q_learning.ipynb` | State-action loops, Q-tables |
| `02_policy_gradients_and_reward_shaping.ipynb` | Train policies directly |
| `03_multi_armed_bandits_and_exploration_strategies.ipynb` | Greedy vs UCB vs Thompson Sampling |
| `04_deep_q_networks_with_openai_gym.ipynb` | From tables to DNNs |
| `05_actor_critic_methods_and_ppo.ipynb` | Modern policy optimization |
| `06_rl_in_real_world_applications.ipynb` | Robotics, games, finance, dialogue |

---

## ðŸ§ª 4. Model Evaluation & Interpretation

> _Metrics that matter, and interpretability tools._

| Notebook | Topic |
|----------|-------|
| `01_metrics_for_imbalanced_datasets.ipynb` | Precision, recall, F1, ROC, AUC |
| `02_cross_validation_strategies.ipynb` | K-fold, stratified, time series CV |
| `03_bias_variance_analysis.ipynb` | Learning curves, capacity tradeoffs |
| `04_model_interpretability_with_shap_lime.ipynb` | Local and global explanations |
| `05_statistical_tests_for_model_comparison.ipynb` | Paired t-tests, significance levels |
| `06_ml_model_auditing_and_fairness.ipynb` | Bias detection, ethical ML checklists |

---

## ðŸ”§ How to Use This Book

âœ… Each notebook includes:
- Code demos + plots
- Feynman-style explanations
- Colab-friendly sections
- ðŸ”¥ Challenges at the end (real dev use cases)

