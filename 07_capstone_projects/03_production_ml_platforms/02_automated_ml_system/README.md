# 02 Automated Ml System

- [autogluon vs h2oai](./autogluon_vs_h2oai.ipynb)
- [ci cd github actions](./ci_cd_github_actions.ipynb)
- [cost monitoring](./cost_monitoring.ipynb)
- [hyperparameter optimization](./hyperparameter_optimization.ipynb)

---

### ⚡ **01. AutoML Benchmarking: AutoGluon vs H2O.ai**

#### 📌 **Subtopics Covered:**
- Setup and quick-start comparison of **AutoGluon** and **H2O.ai**  
- Dataset ingestion, preprocessing, model training  
- Leaderboard comparison: accuracy, time, interpretability  
- Pros/cons for real-world deployment scenarios  

---

### 🔁 **02. CI/CD for ML with GitHub Actions**

#### 📌 **Subtopics Covered:**
- Creating `.github/workflows` for ML pipelines  
- Triggering on data/model changes or pull requests  
- Steps: test → build → train → deploy → monitor  
- Caching datasets, secrets management, environment matrix  

---

### 💸 **03. Cost Monitoring & Optimization**

#### 📌 **Subtopics Covered:**
- Tracking compute, GPU, and inference costs  
- Using cloud tools: AWS Cost Explorer, GCP Billing  
- Optimizing inference: batching, serverless, quantization  
- Monthly usage dashboards with alerts  

---

### 🧠 **04. Hyperparameter Optimization at Scale**

#### 📌 **Subtopics Covered:**
- Grid Search vs Random Search vs **Bayesian Optimization**  
- Tools: Optuna, Ray Tune, HPO with AutoGluon  
- Early stopping, pruning bad trials  
- Parallel execution and resource-aware tuning  

---

### 🛡️ **05. Ethics Review Board Report** (`ethics_review_board_report.md`)

#### 📌 **Contents Covered:**
- AI fairness: transparency, bias mitigation steps  
- Explainability measures in AutoML workflows  
- Risk assessments: data leakage, adversarial threats  
- Compliance with internal/external AI standards  

---

### ✅ Summary

> This capstone reflects a **production-grade AutoML system**, combining automation, accountability, and scalability — all backed by a transparent pipeline and cost-awareness.

---
