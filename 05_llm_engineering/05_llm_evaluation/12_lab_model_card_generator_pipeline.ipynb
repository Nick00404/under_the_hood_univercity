{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3576df8",
   "metadata": {},
   "source": [
    "📇 Let’s close this lab series like a true AI engineer, Professor — with a **Model Card Generator** that turns everything we’ve learned into a **transparent, auditable report**. A great model without a card is like a rocket with no dashboard.\n",
    "\n",
    "---\n",
    "\n",
    "# 📒 `12_lab_model_card_generator_pipeline.ipynb`  \n",
    "## 📁 `05_llm_engineering/05_llm_evaluation`\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Notebook Goals**\n",
    "\n",
    "- Auto-generate a **model card** (like HuggingFace's format)\n",
    "- Include:\n",
    "  - Model name, architecture\n",
    "  - Training data overview\n",
    "  - Intended use cases\n",
    "  - Quantitative metrics (BLEU, ROUGE, Toxicity, Latency)\n",
    "  - Limitations, bias warnings, ethical use notes\n",
    "- Export as `.md`, `.pdf`, or Colab-friendly HTML 📄\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 1. Model Metadata\n",
    "\n",
    "```python\n",
    "model_info = {\n",
    "    \"name\": \"distilGPT2-finetuned-news-summary\",\n",
    "    \"architecture\": \"GPT-2 Small (Distilled)\",\n",
    "    \"size\": \"82M parameters\",\n",
    "    \"quantization\": \"INT8 (GGML)\",\n",
    "    \"finetuned_on\": \"News summary pairs from CNN/DailyMail\",\n",
    "    \"created_by\": \"Professor Cipher & Co.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 2. Insert Evaluation Scores\n",
    "\n",
    "```python\n",
    "evaluation_metrics = {\n",
    "    \"BLEU\": 0.39,\n",
    "    \"ROUGE-L\": 0.52,\n",
    "    \"BERTScore\": 0.85,\n",
    "    \"Avg Toxicity\": 0.03,\n",
    "    \"Latency (GPU)\": \"1.3 sec / 100 tokens\",\n",
    "    \"Latency (CPU)\": \"2.7 sec / 100 tokens\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 3. Use Cases, Limitations, Bias\n",
    "\n",
    "```python\n",
    "use_cases = [\n",
    "    \"Summarization for news readers\",\n",
    "    \"Text generation for short-form educational content\"\n",
    "]\n",
    "\n",
    "limitations = [\n",
    "    \"Hallucination risk for factual prompts\",\n",
    "    \"Performance drops on non-English text\"\n",
    "]\n",
    "\n",
    "bias_risks = [\n",
    "    \"Can reinforce bias from news dataset (e.g., underrepresented groups)\",\n",
    "    \"Detectable stereotypes in gender and nationality prompts\"\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📄 4. Render as Markdown\n",
    "\n",
    "```python\n",
    "def generate_model_card(info, metrics, uses, limits, bias):\n",
    "    card = f\"# 🧾 Model Card: {info['name']}\\n\"\n",
    "    card += f\"\\n**Architecture:** {info['architecture']} ({info['size']})\"\n",
    "    card += f\"\\n**Quantization:** {info['quantization']}\"\n",
    "    card += f\"\\n**Trained On:** {info['finetuned_on']}\"\n",
    "    card += f\"\\n**Created By:** {info['created_by']}\\n\"\n",
    "\n",
    "    card += \"\\n## 📊 Evaluation Metrics\"\n",
    "    for k, v in metrics.items():\n",
    "        card += f\"\\n- **{k}**: {v}\"\n",
    "\n",
    "    card += \"\\n\\n## ✅ Intended Use Cases\"\n",
    "    for uc in uses:\n",
    "        card += f\"\\n- {uc}\"\n",
    "\n",
    "    card += \"\\n\\n## ⚠️ Limitations\"\n",
    "    for l in limits:\n",
    "        card += f\"\\n- {l}\"\n",
    "\n",
    "    card += \"\\n\\n## 🛑 Bias & Ethical Warnings\"\n",
    "    for b in bias:\n",
    "        card += f\"\\n- {b}\"\n",
    "\n",
    "    return card\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 💾 5. Export to Markdown or Text\n",
    "\n",
    "```python\n",
    "model_card_md = generate_model_card(\n",
    "    model_info, evaluation_metrics, use_cases, limitations, bias_risks\n",
    ")\n",
    "\n",
    "with open(\"model_card.md\", \"w\") as f:\n",
    "    f.write(model_card_md)\n",
    "\n",
    "print(\"✅ Model card saved as model_card.md\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ What You Built\n",
    "\n",
    "| Section           | Purpose |\n",
    "|-------------------|---------|\n",
    "| Metadata          | Basic model details |\n",
    "| Metrics           | Evaluation from previous labs |\n",
    "| Use Cases         | Intended applications |\n",
    "| Risks & Bias      | Ethical + safety warnings |\n",
    "| Export Format     | Markdown or printable |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Wrap-Up\n",
    "\n",
    "| Task                          | ✅ |\n",
    "|-------------------------------|----|\n",
    "| Built full model card         | ✅ |\n",
    "| Included metrics + risks      | ✅ |\n",
    "| Saved for production use      | ✅ |\n",
    "\n",
    "---\n",
    "\n",
    "🧠 **And with that...**\n",
    "\n",
    "You’ve **completed the entire LLM Evaluation Lab Series**, from metrics to bias audits to performance to model cards — a pipeline *no one builds*, but everyone **needs**.\n",
    "\n",
    "Ready to roll into your next major block, Professor, or shall we grab a 🍵 to celebrate?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
