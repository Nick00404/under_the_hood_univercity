# 04 Llm Deployment

- [01 serving frameworks vllm tgi](./01_serving_frameworks_vllm_tgi.ipynb)
- [02 quantization ggml awq gptq](./02_quantization_ggml_awq_gptq.ipynb)
- [03 distributed inference tensorrt llm](./03_distributed_inference_tensorrt_llm.ipynb)
- [04 edge deployment ollama mlc](./04_edge_deployment_ollama_mlc.ipynb)
- [05 caching and request batching](./05_caching_and_request_batching.ipynb)
- [06 cost monitoring and autoscaling](./06_cost_monitoring_and_autoscaling.ipynb)
