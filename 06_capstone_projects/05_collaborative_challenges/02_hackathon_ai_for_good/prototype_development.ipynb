{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prototype_development.ipynb\n",
                "\n",
                "# -------------------------------\n",
                "# 1. Setup & Install Dependencies\n",
                "# -------------------------------\n",
                "!pip install transformers datasets flask -q\n",
                "\n",
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "from datasets import load_dataset\n",
                "from flask import Flask, request, jsonify\n",
                "import random\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(\"Running on:\", device)\n",
                "\n",
                "# -------------------------------\n",
                "# 2. Load Model & Tokenizer\n",
                "# -------------------------------\n",
                "model_name = \"distilbert-base-multilingual-cased\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
                "\n",
                "# -------------------------------\n",
                "# 3. Load Dataset (Crisis-Related Queries)\n",
                "# -------------------------------\n",
                "dataset = load_dataset(\"civil_comments\", split=\"train[:1000]\")\n",
                "comments = dataset[\"text\"]\n",
                "\n",
                "# Simulating intent labels\n",
                "intent_labels = [\"mental_health\", \"legal_aid\", \"domestic_violence\", \"general_help\"]\n",
                "random.seed(42)\n",
                "\n",
                "# -------------------------------\n",
                "# 4. Simple Intent Classification\n",
                "# -------------------------------\n",
                "def classify_intent(text):\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.softmax(outputs.logits, dim=-1)\n",
                "    intent = intent_labels[torch.argmax(probs)]\n",
                "    return intent, probs.max().item()\n",
                "\n",
                "# -------------------------------\n",
                "# 5. Flask API for Real-Time Queries\n",
                "# -------------------------------\n",
                "app = Flask(__name__)\n",
                "\n",
                "@app.route('/predict', methods=['POST'])\n",
                "def predict():\n",
                "    data = request.json\n",
                "    query = data.get('query')\n",
                "    \n",
                "    if query:\n",
                "        intent, confidence = classify_intent(query)\n",
                "        response = {\n",
                "            \"intent\": intent,\n",
                "            \"confidence\": confidence,\n",
                "            \"message\": f\"Your query was classified as {intent} with {confidence*100:.2f}% confidence.\"\n",
                "        }\n",
                "    else:\n",
                "        response = {\"error\": \"No query provided\"}\n",
                "    \n",
                "    return jsonify(response)\n",
                "\n",
                "# -------------------------------\n",
                "# 6. Run the Flask App (locally or on Heroku)\n",
                "# -------------------------------\n",
                "if __name__ == \"__main__\":\n",
                "    app.run(debug=True)\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
